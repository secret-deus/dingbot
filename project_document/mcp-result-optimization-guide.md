# MCP工具调用结果优化指南

## 概述

为了解决MCP工具调用结果过大导致LLM上下文溢出的问题，我们实现了一套智能的结果处理和上下文管理系统。

## 核心功能

### 1. 智能结果大小检测

系统会自动检测MCP工具调用结果的大小：
- **字符限制**: 50,000字符 (约50KB)
- **行数限制**: 1,000行
- **摘要目标**: 8,000字符

### 2. 智能关键信息提炼

当结果过大时，系统会根据工具类型采用不同的提炼策略：

#### Kubernetes工具 (`k8s_*`)
- 优先保留状态信息（status, ready, running, failed等）
- 保留统计数据和摘要信息
- 保留表格头部和关键资源信息
- 过滤掉冗余的详细信息

#### 日志工具 (`*log*`)
- 优先保留错误和警告日志
- 按日志级别分类处理
- 限制普通信息日志的数量

#### 通用工具
- 保留开头和结尾的重要信息
- 智能省略中间的冗余内容

### 3. 分页建议系统

当结果被优化时，系统会自动生成针对性的分页建议：

```
💡 建议使用分页参数：--limit=20 --namespace=specific-namespace
💡 或使用标签选择器：--selector=app=your-app
💡 建议限制日志行数：--tail=100 --since=1h
💡 如需完整数据，请使用更具体的查询条件
```

### 4. 上下文管理优化

系统会智能管理对话上下文：
- **最大上下文**: 100,000 tokens（估算）
- **最大历史消息**: 20条
- 保留系统消息和最近的完整对话循环
- 自动添加上下文摘要信息

## 配置参数

在 `backend/src/llm/processor.py` 中的配置：

```python
# 结果大小管理配置
MAX_RESULT_SIZE = 50000  # 50KB 字符限制
MAX_RESULT_LINES = 1000  # 最大行数限制
SUMMARY_TARGET_SIZE = 8000  # 摘要目标大小

# 上下文管理配置
MAX_CONTEXT_TOKENS = 100000  # 最大上下文token数（估算）
MAX_HISTORY_MESSAGES = 20  # 最大历史消息数
```

## 使用示例

### 优化前的问题
```
用户: 获取所有Pod信息
系统: [返回10000行Pod信息，导致上下文溢出]
LLM: [无法响应或响应不完整]
```

### 优化后的效果
```
用户: 获取所有Pod信息
系统: [智能提炼关键信息]
- 保留Pod状态摘要
- 显示异常Pod详情
- 提供分页建议

💡 建议使用分页参数：--limit=20 --namespace=specific-namespace
💡 或使用标签选择器：--selector=app=your-app

LLM: 根据提炼的信息，我看到集群中有X个Pod，其中Y个运行正常...
```

## 日志监控

系统会记录优化过程：

```
INFO: 工具 k8s_get_pods 结果过大，正在提炼关键信息...
INFO: 关键信息提炼完成，大小从 150000 减少到 8500
INFO: 上下文过大 (120000 tokens, 25 messages)，正在优化...
INFO: 上下文优化完成: 25 -> 15 messages, 120000 -> 85000 tokens
```

## 最佳实践

### 1. 使用具体的查询条件
- 指定namespace而不是查询所有
- 使用标签选择器过滤资源
- 限制时间范围和日志行数

### 2. 分批处理大量数据
- 使用分页参数
- 按类型或状态分别查询
- 优先查询异常资源

### 3. 监控系统性能
- 关注日志中的优化提示
- 根据建议调整查询参数
- 定期检查上下文使用情况

## 故障排除

### 如果仍然遇到上下文问题
1. 检查是否使用了过于宽泛的查询
2. 考虑进一步减小 `MAX_RESULT_SIZE` 配置
3. 增加更具体的过滤条件
4. 使用多次小查询替代单次大查询

### 如果关键信息丢失
1. 检查提炼策略是否适合您的用例
2. 考虑调整关键词列表
3. 使用更具体的工具和参数
4. 分步骤获取详细信息

## 更新日志

- **2024-01-XX**: 实现智能结果大小检测和关键信息提炼
- **2024-01-XX**: 添加分页建议系统
- **2024-01-XX**: 实现上下文管理优化
- **2024-01-XX**: 完善日志监控和错误处理
