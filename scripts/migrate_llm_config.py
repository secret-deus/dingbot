#!/usr/bin/env python3
"""
LLMé…ç½®è¿ç§»è„šæœ¬
æ”¯æŒç¯å¢ƒå˜é‡åˆ°æ–‡ä»¶é…ç½®çš„è¿ç§»ï¼Œä»¥åŠé…ç½®å¤‡ä»½å’Œæ¢å¤
"""

import os
import sys
import json
import shutil
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from loguru import logger
from dotenv import load_dotenv

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logger.remove()
    logger.add(
        sys.stdout,
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
        level="INFO"
    )

def load_environment():
    """åŠ è½½ç¯å¢ƒå˜é‡"""
    env_files = ["config.env", ".env", "backend/config.env"]
    
    for env_file in env_files:
        if os.path.exists(env_file):
            load_dotenv(env_file, override=True)
            logger.info(f"âœ… åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_file}")
            return env_file
    
    logger.warning("âš ï¸ æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡æ–‡ä»¶ï¼Œä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡")
    return None

def read_env_config() -> Dict[str, Any]:
    """è¯»å–ç¯å¢ƒå˜é‡é…ç½®"""
    config_data = {
        "enabled": os.getenv("LLM_ENABLED", "true").lower() == "true",
        "provider": os.getenv("LLM_PROVIDER", "openai"),
        "model": os.getenv("LLM_MODEL", "gpt-3.5-turbo"),
        "api_key": os.getenv("LLM_API_KEY", ""),
        "base_url": os.getenv("LLM_BASE_URL"),
        "organization": os.getenv("LLM_ORGANIZATION"),
        "api_version": os.getenv("LLM_API_VERSION"),
        "deployment_name": os.getenv("LLM_DEPLOYMENT_NAME"),
        "timeout": int(os.getenv("LLM_TIMEOUT", "30")),
        "max_retries": int(os.getenv("LLM_MAX_RETRIES", "3")),
        "temperature": float(os.getenv("LLM_TEMPERATURE", "0.7")),
        "max_tokens": int(os.getenv("LLM_MAX_TOKENS", "2000")),
        "stream": os.getenv("LLM_STREAM", "false").lower() == "true"
    }
    
    # ç§»é™¤ç©ºå€¼ä½†ä¿ç•™é‡è¦å­—æ®µ
    filtered_config = {}
    important_fields = {"enabled", "provider", "model", "timeout", "max_retries", "temperature", "max_tokens", "stream"}
    
    for key, value in config_data.items():
        if key in important_fields:
            filtered_config[key] = value
        elif value is not None and value != "":
            filtered_config[key] = value
    
    return filtered_config

def create_provider_config(env_config: Dict[str, Any]) -> Dict[str, Any]:
    """ä»ç¯å¢ƒå˜é‡é…ç½®åˆ›å»ºæä¾›å•†é…ç½®"""
    provider_id = env_config.get("provider", "openai")
    
    provider_config = {
        "id": provider_id,
        "name": get_provider_display_name(provider_id),
        "enabled": env_config.get("enabled", True),
        "model": env_config.get("model", "gpt-3.5-turbo"),
        "temperature": env_config.get("temperature", 0.7),
        "max_tokens": env_config.get("max_tokens", 2000),
        "timeout": env_config.get("timeout", 30),
        "max_retries": env_config.get("max_retries", 3),
        "stream": env_config.get("stream", False)
    }
    
    # æ·»åŠ ç‰¹å®šæä¾›å•†çš„å­—æ®µ
    if env_config.get("api_key"):
        provider_config["api_key"] = env_config["api_key"]
    if env_config.get("base_url"):
        provider_config["base_url"] = env_config["base_url"]
    if env_config.get("organization"):
        provider_config["organization"] = env_config["organization"]
    if env_config.get("api_version"):
        provider_config["api_version"] = env_config["api_version"]
    if env_config.get("deployment_name"):
        provider_config["deployment_name"] = env_config["deployment_name"]
    
    return provider_config

def get_provider_display_name(provider_id: str) -> str:
    """è·å–æä¾›å•†æ˜¾ç¤ºåç§°"""
    names = {
        "openai": "OpenAI",
        "azure": "Azure OpenAI",
        "zhipu": "æ™ºè°±AI",
        "qwen": "é€šä¹‰åƒé—®",
        "deepseek": "DeepSeek",
        "moonshot": "Moonshot AI",
        "ollama": "Ollama",
        "custom": "è‡ªå®šä¹‰API"
    }
    return names.get(provider_id, provider_id.title())

def create_config_from_env(env_config: Dict[str, Any]) -> Dict[str, Any]:
    """ä»ç¯å¢ƒå˜é‡åˆ›å»ºå®Œæ•´é…ç½®"""
    provider_config = create_provider_config(env_config)
    
    config = {
        "version": "1.0",
        "name": "LLMé…ç½®",
        "description": f"ä»ç¯å¢ƒå˜é‡è¿ç§»ç”Ÿæˆäº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        "default_provider": env_config.get("provider", "openai"),
        "providers": [provider_config],
        "global_settings": {
            "timeout": env_config.get("timeout", 30),
            "max_retries": env_config.get("max_retries", 3),
            "enable_cache": True,
            "cache_timeout": 300
        }
    }
    
    return config

def backup_existing_config(config_file: Path) -> Optional[Path]:
    """å¤‡ä»½ç°æœ‰é…ç½®æ–‡ä»¶"""
    if not config_file.exists():
        return None
        
    backup_dir = config_file.parent / "backups"
    backup_dir.mkdir(parents=True, exist_ok=True)
    
    backup_filename = f"llm_config_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    backup_path = backup_dir / backup_filename
    
    shutil.copy2(config_file, backup_path)
    logger.info(f"âœ… å·²å¤‡ä»½ç°æœ‰é…ç½®: {backup_path}")
    
    return backup_path

def migrate_to_file_config(target_file: str = "config/llm_config.json", force: bool = False) -> bool:
    """å°†ç¯å¢ƒå˜é‡é…ç½®è¿ç§»åˆ°æ–‡ä»¶é…ç½®"""
    config_file = Path(target_file)
    
    # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if config_file.exists() and not force:
        logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶å·²å­˜åœ¨: {config_file}")
        logger.info("ä½¿ç”¨ --force å‚æ•°å¼ºåˆ¶è¦†ç›–ç°æœ‰é…ç½®")
        return False
    
    # å¤‡ä»½ç°æœ‰é…ç½®
    if config_file.exists():
        backup_path = backup_existing_config(config_file)
        if backup_path:
            logger.info(f"ğŸ“¦ å·²åˆ›å»ºå¤‡ä»½: {backup_path}")
    
    # åˆ›å»ºç›®æ ‡ç›®å½•
    config_file.parent.mkdir(parents=True, exist_ok=True)
    
    # è¯»å–ç¯å¢ƒå˜é‡é…ç½®
    env_config = read_env_config()
    logger.info(f"ğŸ“– è¯»å–åˆ°ç¯å¢ƒå˜é‡é…ç½®: {env_config.get('provider', 'unknown')} - {env_config.get('model', 'unknown')}")
    
    # åˆ›å»ºæ–‡ä»¶é…ç½®
    file_config = create_config_from_env(env_config)
    
    # ä¿å­˜é…ç½®æ–‡ä»¶
    try:
        with open(config_file, "w", encoding="utf-8") as f:
            json.dump(file_config, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… é…ç½®è¿ç§»æˆåŠŸ: {config_file}")
        
        # åˆ›å»ºè¿ç§»è®°å½•
        migration_log = {
            "migration_type": "env_to_file",
            "source": "environment_variables",
            "target": str(config_file),
            "timestamp": datetime.now().isoformat(),
            "env_config": env_config,
            "status": "success"
        }
        
        migration_log_file = config_file.parent / "migration.log"
        with open(migration_log_file, "w", encoding="utf-8") as f:
            json.dump(migration_log, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“ è¿ç§»è®°å½•: {migration_log_file}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return False

def rollback_to_env_config(config_file: str = "config/llm_config.json") -> bool:
    """å›é€€åˆ°ç¯å¢ƒå˜é‡é…ç½®ï¼ˆåˆ é™¤æ–‡ä»¶é…ç½®ï¼‰"""
    config_path = Path(config_file)
    
    if not config_path.exists():
        logger.info("âœ… é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå·²ç»æ˜¯ç¯å¢ƒå˜é‡æ¨¡å¼")
        return True
    
    # åˆ›å»ºå›é€€å¤‡ä»½
    backup_path = backup_existing_config(config_path)
    
    try:
        config_path.unlink()
        logger.info(f"âœ… å·²åˆ é™¤é…ç½®æ–‡ä»¶: {config_file}")
        logger.info("ğŸ”„ ç³»ç»Ÿå°†å›é€€åˆ°ç¯å¢ƒå˜é‡é…ç½®æ¨¡å¼")
        
        if backup_path:
            logger.info(f"ğŸ“¦ é…ç½®å·²å¤‡ä»½åˆ°: {backup_path}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ åˆ é™¤é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return False

def list_backups(config_dir: str = "config") -> None:
    """åˆ—å‡ºæ‰€æœ‰é…ç½®å¤‡ä»½"""
    backup_dir = Path(config_dir) / "backups"
    
    if not backup_dir.exists():
        logger.info("ğŸ“‚ å¤‡ä»½ç›®å½•ä¸å­˜åœ¨")
        return
    
    backup_files = list(backup_dir.glob("*.json"))
    
    if not backup_files:
        logger.info("ğŸ“‚ æ²¡æœ‰æ‰¾åˆ°é…ç½®å¤‡ä»½")
        return
    
    logger.info("ğŸ“‹ é…ç½®å¤‡ä»½åˆ—è¡¨:")
    for backup_file in sorted(backup_files, reverse=True):
        stat = backup_file.stat()
        size_mb = stat.st_size / (1024 * 1024)
        modified_time = datetime.fromtimestamp(stat.st_mtime)
        
        logger.info(f"  ğŸ“„ {backup_file.name}")
        logger.info(f"     å¤§å°: {size_mb:.2f} MB")
        logger.info(f"     æ—¶é—´: {modified_time.strftime('%Y-%m-%d %H:%M:%S')}")

def restore_backup(backup_name: str, config_dir: str = "config") -> bool:
    """ä»å¤‡ä»½æ¢å¤é…ç½®"""
    backup_dir = Path(config_dir) / "backups"
    backup_file = backup_dir / backup_name
    config_file = Path(config_dir) / "llm_config.json"
    
    if not backup_file.exists():
        logger.error(f"âŒ å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_file}")
        return False
    
    try:
        # å¤‡ä»½å½“å‰é…ç½®
        if config_file.exists():
            current_backup = backup_existing_config(config_file)
            logger.info(f"ğŸ“¦ å½“å‰é…ç½®å·²å¤‡ä»½: {current_backup}")
        
        # æ¢å¤å¤‡ä»½
        shutil.copy2(backup_file, config_file)
        logger.info(f"âœ… å·²ä»å¤‡ä»½æ¢å¤é…ç½®: {backup_name}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ¢å¤å¤‡ä»½å¤±è´¥: {e}")
        return False

def validate_config(config_file: str = "config/llm_config.json") -> bool:
    """éªŒè¯é…ç½®æ–‡ä»¶"""
    config_path = Path(config_file)
    
    if not config_path.exists():
        logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return False
    
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            config_data = json.load(f)
        
        # åŸºæœ¬ç»“æ„éªŒè¯
        required_fields = ["version", "name", "providers"]
        missing_fields = [field for field in required_fields if field not in config_data]
        
        if missing_fields:
            logger.error(f"âŒ é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}")
            return False
        
        # æä¾›å•†éªŒè¯
        providers = config_data.get("providers", [])
        if not providers:
            logger.warning("âš ï¸ é…ç½®æ–‡ä»¶æ²¡æœ‰æä¾›å•†é…ç½®")
            return False
        
        enabled_providers = [p for p in providers if p.get("enabled", True)]
        logger.info(f"âœ… é…ç½®éªŒè¯é€šè¿‡")
        logger.info(f"ğŸ“Š æ€»æä¾›å•†: {len(providers)}, å·²å¯ç”¨: {len(enabled_providers)}")
        
        # æ˜¾ç¤ºæä¾›å•†ä¿¡æ¯
        for provider in providers:
            status = "âœ…" if provider.get("enabled", True) else "âŒ"
            logger.info(f"  {status} {provider.get('name', provider.get('id', 'Unknown'))}: {provider.get('model', 'N/A')}")
        
        return True
        
    except json.JSONDecodeError as e:
        logger.error(f"âŒ é…ç½®æ–‡ä»¶JSONæ ¼å¼é”™è¯¯: {e}")
        return False
    except Exception as e:
        logger.error(f"âŒ é…ç½®æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="LLMé…ç½®è¿ç§»å·¥å…·")
    
    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")
    
    # è¿ç§»å‘½ä»¤
    migrate_parser = subparsers.add_parser("migrate", help="å°†ç¯å¢ƒå˜é‡é…ç½®è¿ç§»åˆ°æ–‡ä»¶")
    migrate_parser.add_argument("--target", default="config/llm_config.json", help="ç›®æ ‡é…ç½®æ–‡ä»¶è·¯å¾„")
    migrate_parser.add_argument("--force", action="store_true", help="å¼ºåˆ¶è¦†ç›–ç°æœ‰é…ç½®æ–‡ä»¶")
    
    # å›é€€å‘½ä»¤
    rollback_parser = subparsers.add_parser("rollback", help="å›é€€åˆ°ç¯å¢ƒå˜é‡é…ç½®")
    rollback_parser.add_argument("--config", default="config/llm_config.json", help="è¦åˆ é™¤çš„é…ç½®æ–‡ä»¶è·¯å¾„")
    
    # å¤‡ä»½å‘½ä»¤
    backup_parser = subparsers.add_parser("list-backups", help="åˆ—å‡ºæ‰€æœ‰é…ç½®å¤‡ä»½")
    backup_parser.add_argument("--dir", default="config", help="é…ç½®ç›®å½•")
    
    # æ¢å¤å‘½ä»¤
    restore_parser = subparsers.add_parser("restore", help="ä»å¤‡ä»½æ¢å¤é…ç½®")
    restore_parser.add_argument("backup_name", help="å¤‡ä»½æ–‡ä»¶å")
    restore_parser.add_argument("--dir", default="config", help="é…ç½®ç›®å½•")
    
    # éªŒè¯å‘½ä»¤
    validate_parser = subparsers.add_parser("validate", help="éªŒè¯é…ç½®æ–‡ä»¶")
    validate_parser.add_argument("--config", default="config/llm_config.json", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    
    # çŠ¶æ€å‘½ä»¤
    status_parser = subparsers.add_parser("status", help="æ˜¾ç¤ºé…ç½®çŠ¶æ€")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    setup_logging()
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_environment()
    
    if args.command == "migrate":
        success = migrate_to_file_config(args.target, args.force)
        sys.exit(0 if success else 1)
        
    elif args.command == "rollback":
        success = rollback_to_env_config(args.config)
        sys.exit(0 if success else 1)
        
    elif args.command == "list-backups":
        list_backups(args.dir)
        
    elif args.command == "restore":
        success = restore_backup(args.backup_name, args.dir)
        sys.exit(0 if success else 1)
        
    elif args.command == "validate":
        success = validate_config(args.config)
        sys.exit(0 if success else 1)
        
    elif args.command == "status":
        logger.info("ğŸ“Š LLMé…ç½®çŠ¶æ€æ£€æŸ¥")
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        env_config = read_env_config()
        logger.info(f"ğŸŒ ç¯å¢ƒå˜é‡é…ç½®: {env_config.get('provider', 'unknown')} - {env_config.get('model', 'unknown')}")
        
        # æ£€æŸ¥æ–‡ä»¶é…ç½®
        config_file = Path("config/llm_config.json")
        if config_file.exists():
            logger.info("ğŸ“ æ–‡ä»¶é…ç½®: å­˜åœ¨")
            validate_config(str(config_file))
        else:
            logger.info("ğŸ“ æ–‡ä»¶é…ç½®: ä¸å­˜åœ¨ï¼ˆä½¿ç”¨ç¯å¢ƒå˜é‡æ¨¡å¼ï¼‰")
            
        # æ£€æŸ¥è¿ç§»è®°å½•
        migration_log = config_file.parent / "migration.log" if config_file.parent.exists() else None
        if migration_log and migration_log.exists():
            logger.info(f"ğŸ“ è¿ç§»è®°å½•: å­˜åœ¨ ({migration_log})")
        else:
            logger.info("ğŸ“ è¿ç§»è®°å½•: ä¸å­˜åœ¨")
            
    else:
        parser.print_help()

if __name__ == "__main__":
    main() 