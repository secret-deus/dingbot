"""Ollama LLMé€‚é…å™¨ - æ”¯æŒç»“æ„åŒ–è¾“å‡ºå’Œä¼ªå·¥å…·è°ƒç”¨"""

import json
import httpx
import asyncio
from typing import Dict, Any, List, Optional, Union
from loguru import logger


class OllamaAdapter:
    """Ollama LLMé€‚é…å™¨ï¼Œé€šè¿‡Prompt Engineeringå®ç°å·¥å…·è°ƒç”¨æ•ˆæœ"""
    
    def __init__(self, base_url: str = "http://localhost:11434", model: str = "llama3.1:8b"):
        self.base_url = base_url.rstrip('/')
        self.model = model
        self.client = httpx.AsyncClient(timeout=120.0)
        
    async def generate_yaml(self, requirements: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ç”ŸæˆKubernetes YAMLé…ç½®"""
        try:
            prompt = self._build_yaml_prompt(requirements, context or {})
            
            # è°ƒç”¨Ollama API
            response = await self._call_ollama(prompt, response_format="json")
            
            # è§£æå“åº”
            result = self._parse_yaml_response(response)
            
            return {
                "success": True,
                "yaml_content": result.get("yaml", ""),
                "explanation": result.get("explanation", ""),
                "warnings": result.get("warnings", [])
            }
            
        except Exception as e:
            logger.error(f"Ollama YAMLç”Ÿæˆå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "yaml_content": "",
                "explanation": "",
                "warnings": []
            }
    
    def _build_yaml_prompt(self, requirements: str, context: Dict[str, Any]) -> str:
        """æ„å»ºä¼˜åŒ–çš„Prompt"""
        
        system_instruction = """ä½ æ˜¯ä¸€ä¸ªKubernetesä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·éœ€æ±‚ç”Ÿæˆæ ‡å‡†çš„Deployment YAMLé…ç½®ã€‚

CRITICAL: ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—ï¼š

{
  "yaml": "å®Œæ•´çš„YAMLé…ç½®å†…å®¹ï¼ˆä½¿ç”¨\\nè¡¨ç¤ºæ¢è¡Œï¼‰",
  "explanation": "ç®€è¦è¯´æ˜ç”Ÿæˆçš„é…ç½®ç‰¹ç‚¹",
  "warnings": ["å¦‚æœæœ‰ä»»ä½•æ³¨æ„äº‹é¡¹ï¼Œåœ¨è¿™é‡Œåˆ—å‡º"]
}"""

        user_prompt = f"""
ç”¨æˆ·éœ€æ±‚: {requirements}

ä¸Šä¸‹æ–‡ä¿¡æ¯:
- å‘½åç©ºé—´: {context.get('namespace', 'default')}
- ç¯å¢ƒç±»å‹: {context.get('environment', 'production')}
- èµ„æºé™åˆ¶: {context.get('constraints', {})}

ç”Ÿæˆè¦æ±‚:
1. ç”Ÿæˆå®Œæ•´çš„Kubernetes Deployment YAML
2. åŒ…å«ç”Ÿäº§çº§å®‰å…¨é…ç½®
3. æ·»åŠ å¥åº·æ£€æŸ¥ï¼ˆliveness/readiness probesï¼‰
4. è®¾ç½®åˆç†çš„èµ„æºé™åˆ¶
5. åŒ…å«æ»šåŠ¨æ›´æ–°ç­–ç•¥
6. ç¡®ä¿YAMLæ ¼å¼æ­£ç¡®

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼å›å¤ã€‚"""

        return f"{system_instruction}\n\n{user_prompt}"
    
    async def _call_ollama(self, prompt: str, response_format: str = "json") -> str:
        """è°ƒç”¨Ollama API"""
        
        payload = {
            "model": self.model,
            "prompt": prompt,
            "stream": False,
            "format": response_format if response_format == "json" else None,
            "options": {
                "temperature": 0.1,  # è¾ƒä½æ¸©åº¦ç¡®ä¿ä¸€è‡´æ€§
                "top_p": 0.9,
                "top_k": 40,
                "num_predict": 2048  # å…è®¸è¾ƒé•¿çš„è¾“å‡º
            }
        }
        
        logger.info(f"ğŸ¤– è°ƒç”¨Ollamaæ¨¡å‹: {self.model}")
        
        response = await self.client.post(
            f"{self.base_url}/api/generate",
            json=payload
        )
        
        if response.status_code != 200:
            raise Exception(f"Ollama APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
        
        result = response.json()
        return result.get("response", "")
    
    def _parse_yaml_response(self, response: str) -> Dict[str, Any]:
        """è§£æOllamaçš„JSONå“åº”"""
        try:
            # å°è¯•ç›´æ¥è§£æJSON
            parsed = json.loads(response)
            return parsed
            
        except json.JSONDecodeError:
            # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æå–JSONéƒ¨åˆ†
            logger.warning("ç›´æ¥JSONè§£æå¤±è´¥ï¼Œå°è¯•æå–JSONå†…å®¹")
            
            # æŸ¥æ‰¾JSONå—
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                try:
                    parsed = json.loads(json_match.group())
                    return parsed
                except json.JSONDecodeError:
                    pass
            
            # å¦‚æœä»ç„¶å¤±è´¥ï¼Œè¿”å›åŸå§‹å“åº”ä½œä¸ºYAML
            logger.warning("JSONæå–å¤±è´¥ï¼Œå°†åŸå§‹å“åº”ä½œä¸ºYAMLå¤„ç†")
            return {
                "yaml": response,
                "explanation": "ç”±äºå“åº”æ ¼å¼é—®é¢˜ï¼Œæ— æ³•æä¾›è¯¦ç»†è§£æ",
                "warnings": ["å“åº”æ ¼å¼ä¸æ˜¯æ ‡å‡†JSONï¼Œè¯·æ£€æŸ¥ç”Ÿæˆçš„YAML"]
            }
    
    async def analyze_requirements(self, requirements: str) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·éœ€æ±‚ï¼Œæå–å…³é”®ä¿¡æ¯"""
        
        prompt = f"""
åˆ†æä»¥ä¸‹Kuberneteséƒ¨ç½²éœ€æ±‚ï¼Œæå–å…³é”®ä¿¡æ¯ï¼š

ç”¨æˆ·éœ€æ±‚: {requirements}

è¯·ä»¥JSONæ ¼å¼å›å¤ï¼ŒåŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š
{{
  "app_name": "æ¨æ–­çš„åº”ç”¨åç§°",
  "image": "æ¨èçš„å®¹å™¨é•œåƒ",
  "replicas": æ¨èçš„å‰¯æœ¬æ•°,
  "ports": [æ¨èçš„ç«¯å£é…ç½®],
  "environment": "æ¨æ–­çš„ç¯å¢ƒç±»å‹(development/staging/production)",
  "resources_needed": "èµ„æºéœ€æ±‚è¯„ä¼°",
  "security_level": "å®‰å…¨çº§åˆ«(low/medium/high)",
  "additional_components": ["å¯èƒ½éœ€è¦çš„é¢å¤–ç»„ä»¶åˆ—è¡¨"]
}}
"""
        
        try:
            response = await self._call_ollama(prompt, "json")
            return json.loads(response)
        except Exception as e:
            logger.error(f"éœ€æ±‚åˆ†æå¤±è´¥: {e}")
            return {}
    
    async def close(self):
        """å…³é—­HTTPå®¢æˆ·ç«¯"""
        await self.client.aclose()


class OllamaToolManager:
    """Ollamaå·¥å…·ç®¡ç†å™¨ - æ¨¡æ‹Ÿå·¥å…·è°ƒç”¨åŠŸèƒ½"""
    
    def __init__(self, ollama_adapter: OllamaAdapter):
        self.adapter = ollama_adapter
        self.available_tools = {
            "generate_deployment_yaml": self._generate_deployment_yaml,
            "analyze_requirements": self._analyze_requirements,
            "suggest_optimizations": self._suggest_optimizations
        }
    
    async def execute_tool(self, tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒæŒ‡å®šçš„å·¥å…·"""
        if tool_name not in self.available_tools:
            return {
                "success": False,
                "error": f"æœªçŸ¥å·¥å…·: {tool_name}",
                "available_tools": list(self.available_tools.keys())
            }
        
        try:
            result = await self.available_tools[tool_name](arguments)
            return {"success": True, "result": result}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _generate_deployment_yaml(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ç”ŸæˆDeployment YAML"""
        requirements = args.get("requirements", "")
        context = args.get("context", {})
        
        return await self.adapter.generate_yaml(requirements, context)
    
    async def _analyze_requirements(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æéœ€æ±‚"""
        requirements = args.get("requirements", "")
        return await self.adapter.analyze_requirements(requirements)
    
    async def _suggest_optimizations(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """å»ºè®®ä¼˜åŒ–æ–¹æ¡ˆ"""
        yaml_content = args.get("yaml_content", "")
        
        prompt = f"""
åˆ†æä»¥ä¸‹Kubernetes YAMLé…ç½®ï¼Œæä¾›ä¼˜åŒ–å»ºè®®ï¼š

YAMLé…ç½®:
{yaml_content}

è¯·ä»¥JSONæ ¼å¼æä¾›ä¼˜åŒ–å»ºè®®ï¼š
{{
  "performance_optimizations": ["æ€§èƒ½ä¼˜åŒ–å»ºè®®"],
  "security_improvements": ["å®‰å…¨æ€§æ”¹è¿›"],
  "resource_optimizations": ["èµ„æºä¼˜åŒ–å»ºè®®"],
  "best_practices": ["æœ€ä½³å®è·µå»ºè®®"],
  "potential_issues": ["æ½œåœ¨é—®é¢˜"]
}}
"""
        
        try:
            response = await self.adapter._call_ollama(prompt, "json")
            return json.loads(response)
        except Exception as e:
            logger.error(f"ä¼˜åŒ–å»ºè®®ç”Ÿæˆå¤±è´¥: {e}")
            return {"error": str(e)}


# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•å‡½æ•°
async def demo_ollama_tools():
    """æ¼”ç¤ºOllamaå·¥å…·è°ƒç”¨åŠŸèƒ½"""
    print("ğŸ¤– Ollama LLMå·¥å…·è°ƒç”¨æ¼”ç¤º")
    print("=" * 50)
    
    # åˆå§‹åŒ–é€‚é…å™¨
    adapter = OllamaAdapter(model="llama3.1:8b")  # æˆ–å…¶ä»–æ”¯æŒçš„æ¨¡å‹
    tool_manager = OllamaToolManager(adapter)
    
    try:
        # æµ‹è¯•éœ€æ±‚åˆ†æ
        print("\nğŸ“‹ 1. éœ€æ±‚åˆ†æ")
        analysis_result = await tool_manager.execute_tool(
            "analyze_requirements",
            {"requirements": "æˆ‘éœ€è¦éƒ¨ç½²ä¸€ä¸ªé«˜æ€§èƒ½çš„nginx webæœåŠ¡å™¨ï¼Œç”Ÿäº§ç¯å¢ƒï¼Œ3ä¸ªå‰¯æœ¬"}
        )
        
        if analysis_result["success"]:
            print("âœ… éœ€æ±‚åˆ†ææˆåŠŸ:")
            result = analysis_result["result"]
            print(f"   åº”ç”¨å: {result.get('app_name', 'N/A')}")
            print(f"   æ¨èé•œåƒ: {result.get('image', 'N/A')}")
            print(f"   å‰¯æœ¬æ•°: {result.get('replicas', 'N/A')}")
            print(f"   ç¯å¢ƒç±»å‹: {result.get('environment', 'N/A')}")
        else:
            print(f"âŒ éœ€æ±‚åˆ†æå¤±è´¥: {analysis_result.get('error')}")
        
        # æµ‹è¯•YAMLç”Ÿæˆ
        print("\nğŸš€ 2. YAMLç”Ÿæˆ")
        yaml_result = await tool_manager.execute_tool(
            "generate_deployment_yaml",
            {
                "requirements": "åˆ›å»ºä¸€ä¸ªRedisç¼“å­˜æœåŠ¡ï¼Œå•å®ä¾‹ï¼Œå¼€å‘ç¯å¢ƒ",
                "context": {
                    "namespace": "dev",
                    "environment": "development"
                }
            }
        )
        
        if yaml_result["success"]:
            result = yaml_result["result"]
            if result["success"]:
                print("âœ… YAMLç”ŸæˆæˆåŠŸ")
                print(f"   è¯´æ˜: {result.get('explanation', '')}")
                if result.get('warnings'):
                    print(f"   è­¦å‘Š: {result['warnings']}")
                # æ˜¾ç¤ºYAMLå‰å‡ è¡Œ
                yaml_lines = result.get('yaml_content', '').split('\\n')[:5]
                print(f"   YAMLé¢„è§ˆ: {' | '.join(yaml_lines)}")
            else:
                print(f"âŒ YAMLç”Ÿæˆå¤±è´¥: {result.get('error')}")
        else:
            print(f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {yaml_result.get('error')}")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
    finally:
        await adapter.close()

if __name__ == "__main__":
    asyncio.run(demo_ollama_tools()) 